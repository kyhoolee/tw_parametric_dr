üìÅ Project Directory Tree (filtered):
/home/kyhoolee/work/1_backend/4_financial_analysis/3_crypto/9_data_science/data_science_challenge/taiwan_phd/prof_papers/code/tw_parametric_dr
‚îú‚îÄ‚îÄ code_summary.txt
‚îú‚îÄ‚îÄ dataset
‚îú‚îÄ‚îÄ docs
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ summary.sh
‚îú‚îÄ‚îÄ document
‚îú‚îÄ‚îÄ img
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ parametric_dr
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ graphutil.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ network.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ tsne_nn.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ test.py
‚îî‚îÄ‚îÄ tutorial.ipynb

6 directories, 12 files


üìÑ README.md:

# Parametric-DR
Parametric Dimension Reduction by Preserving Local Structure

![Teaser image](./img/teaser.png)

> **Abstract:** *We extend a well-known dimension reduction method, t-distributed
stochastic neighbor embedding (t-SNE), from non-parametric to
parametric by training neural networks. The main advantage of a
parametric technique is the generalization of handling new data,
which is beneficial for streaming data visualization. While previous
parametric methods either require a network pre-training by
the restricted Boltzmann machine or intermediate results obtained
from the traditional non-parametric t-SNE, we found that recent
network training skills can enable a direct optimization for the t-
SNE objective function. Accordingly, our method achieves high
embedding quality while enjoying generalization. Due to minibatch
network training, our parametric dimension reduction method
is highly efficient. For evaluation, we compared our method to
several baselines on a variety of datasets. Experiment results demonstrate
the feasibility of our method.*

## Paper & Supplemental material
Download Paper from  <a href="https://github.com/a07458666/parametric_dr/blob/main/document/Parametric_t_SNE_main.pdf">Parametric Dimension Reduction by Preserving Local Structure</a>.

Download  <a href="https://github.com/a07458666/parametric_dr/blob/main/document/Parametric_t_SNE_supplemental.pdf">Supplemental material</a>.


## Prerequisites
* pytorch (https://pytorch.org/)
* opentsne (https://opentsne.readthedocs.io/en/latest/api/index.html)

## <div align="left">Quick Start Examples</div>

<details open>
<summary>Install</summary>
Clone repo and install requirements.txt in a Python>=3.7.0 environment, including PyTorch>=1.7.

```
git clone https://github.com/a07458666/parametric_dr  # clone
cd parametric_dr
pip install -r requirements.txt  # install
```
</details>

<details open>
<summary>Inference</summary>
You can try it in <a href="https://github.com/a07458666/parametric_dr/blob/main/tutorial.ipynb">jupyter note</a>

### TSNE_NN
```python
import numpy as np
import torch
from parametric_dr.tsne_nn import TSNE_NN
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
epochs = 100
batch_size = 256

X = np.random.rand(512, 128)
X_embedded = TSNE_NN(device, n_epochs=epochs, batch_size=batch_size).fit(X)
```
</details>


üìÑ requirements.txt:

openTSNE==0.4.4
torch>=1.7.1
torchaudio>=0.7.2
torchvision>=0.8.2
numpy>=1.20.0


üìÑ test.py:

import os
import numpy as np
import matplotlib.pyplot as plt
import torch 

from scipy import spatial
from sklearn.neighbors import KNeighborsClassifier
from parametric_dr.tsne_nn import TSNE_NN
from parametric_dr.evaluation import metric_continuity, metric_trustworthiness, metric_neighborhood_hit

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
epochs = 200
batch_size = 256
data_size = 5000
verbose = True
name = 'sigmoid'
np.random.seed(0)
torch.manual_seed(0)

# Ë≥áÊñôË∑ØÂæë
dataset_path = './dataset/mnist_60000.npz'
dataset_name = os.path.basename(dataset_path)
dataset = np.load(dataset_path)
perm = np.random.permutation(len(dataset['data']))


# ÂàÜÂâ≤Ë≥áÊñô
X_train = dataset['data'][perm][:data_size]
y_train = dataset['target'][perm][:data_size]
X_test = dataset['data'][perm][data_size:data_size * 2]
y_test = dataset['target'][perm][data_size:data_size * 2]

# Ë®≠ÂÆöÂèÉÊï∏ (perplexity for TSNE, n_neighbors and min_dist for UMAP)
tsne_nn = TSNE_NN(device, n_epochs=epochs, verbose = verbose, batch_size=batch_size)

# Train
X_embedded = tsne_nn.fit(X_train)
X_embedded_test = tsne_nn.fit_val(X_test)

# high dimension data
if not os.path.exists("./results/" + dataset_name + "_D_high.npy"):
    D_high_list = spatial.distance.pdist(X_test, 'euclidean')
    D_high_matrix = spatial.distance.squareform(D_high_list)
    np.save("./results/" + dataset_name + "_D_high.npy", D_high_matrix)
else:
    D_high_matrix = np.load("./results/" + dataset_name + "_D_high.npy")

# low dimension data"
D_low_list = spatial.distance.pdist(X_embedded_test, 'euclidean')
D_low_matrix = spatial.distance.squareform(D_low_list)

print("----------Evaluation----------")
# Continuity
continuity = metric_continuity(D_high_matrix, D_low_matrix, k=7)
print("Continuity = " + str(continuity))
# Trustworthiness
trustworthiness = metric_trustworthiness(D_high_matrix, D_low_matrix, k=7)
print("Trustworthiness = " + str(trustworthiness))
# Neighborhood Hit
neighborhood_hit = metric_neighborhood_hit(X_embedded_test, y_test, k=7)
print("Neighborhood Hit = " + str(neighborhood_hit))
# Average
average = (continuity + trustworthiness + neighborhood_hit) / 3
print("Average = " + str(average))

# Project PNG
x_axis = X_embedded_test[:,0]
y_axis = X_embedded_test[:,1]
c = y_test

plt.figure(figsize=(12, 12))
plt.subplot(221) 
plt.xlim(0,1)
plt.ylim(0,1)
if len(set(c.tolist())) == 10:
    plt.scatter(x_axis, y_axis, c=c, alpha=0.3, cmap='tab10')
        
elif len(set(c.tolist())) == 20:
    plt.scatter(x_axis, y_axis, c=c, alpha=0.3, cmap='tab20')
            
elif len(set(c.tolist())) <= 5:
    cdict = {0: 'tab:blue', 1: 'tab:orange', 2: 'tab:green', 3: 'tab:red', 4: 'tab:purple'}
            
    for color in np.unique(c):
        ix = np.where(c == color)
        plt.scatter(x_axis[ix], y_axis[ix], c=cdict[color], alpha=0.3)
else:
    plt.scatter(x_axis, y_axis, c=c, alpha=0.3)

plt.subplot(222) 
if (len(tsne_nn.max_grads) > 0):
    print("max grad len = ", len(tsne_nn.max_grads))
    print("max grad MAX = ", max(tsne_nn.max_grads))
    max_grads = np.nan_to_num(tsne_nn.max_grads)
    plt.plot(max_grads)

plt.subplot(223) 
if (len(tsne_nn.epoch_losses) > 0):
    epoch_losses = np.nan_to_num(tsne_nn.epoch_losses)
    plt.plot(epoch_losses)

plt.subplot(224) 
table_data=[
    ["Continuity", round(continuity,3)],
    ["Trustworthiness", round(trustworthiness,3)],
    ["Neighborhood Hit", round(neighborhood_hit,3)],
    ["Average", round(average,3)]
]
plt.axis('off')
plt.axis('tight')
the_table = plt.table(cellText=table_data, loc='best')
the_table.auto_set_font_size(False)
the_table.set_fontsize(18)
the_table.scale(1, 2)

plt.savefig('./results/' + name + '.png')

üìÑ tutorial.ipynb (as raw text):

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from parametric_dr.tsne_nn import TSNE_NN\n",
        "from parametric_dr.largevis_nn import LARGEVIS_NN\n",
        "from parametric_dr.umap_nn import UMAP_NN\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "verbose = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TSNE_NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "perplexity: 15\n",
            "calc P\n",
            "Trying to put X into GPU\n",
            "optimizing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 100/100 loss : 2.98586 time : 0.00660s: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 68.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape : (512, 128) \n",
            "X_embedded shape :  (512, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "X = np.random.rand(512, 128)\n",
        "X_embedded = TSNE_NN(device, n_epochs=epochs, verbose = verbose, batch_size=batch_size).fit(X)\n",
        "print(\"X shape :\", X.shape, \"\\nX_embedded shape : \", X_embedded.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}


üìÑ parametric_dr/*.py files:


--- File: evaluation.py ---

import numpy as np
from sklearn.neighbors import KNeighborsClassifier


def metric_continuity(D_high, D_low, k):
    assert D_high.shape == D_low.shape, 'D_high != D_low shape!'
    N_SAMPLES = D_high.shape[0]

    n = N_SAMPLES

    nn_orig = D_high.argsort()
    nn_proj = D_low.argsort()

    knn_orig = nn_orig[:, :k + 1][:, 1:]
    knn_proj = nn_proj[:, :k + 1][:, 1:]

    sum_i = 0

    for i in range(N_SAMPLES):
        V = np.setdiff1d(knn_orig[i], knn_proj[i])

        sum_j = 0
        for j in range(V.shape[0]):
            sum_j += np.where(nn_proj[i] == V[j])[0] - k

        sum_i += sum_j

    return float((1 - (2/(n*k*(2*n - 3*k - 1))*sum_i)).squeeze())

def metric_trustworthiness(D_high, D_low, k):
    assert D_high.shape == D_low.shape, 'D_high != D_low shape!'
    N_SAMPLES = D_high.shape[0]

    n = N_SAMPLES

    nn_orig = D_high.argsort()
    nn_proj = D_low.argsort()

    knn_orig = nn_orig[:, :k + 1][:, 1:]
    knn_proj = nn_proj[:, :k + 1][:, 1:]

    sum_i = 0

    for i in range(n):
        U = np.setdiff1d(knn_proj[i], knn_orig[i])

        sum_j = 0
        for j in range(U.shape[0]):
            sum_j += np.where(nn_orig[i] == U[j])[0] - k

        sum_i += sum_j

    return float((1 - (2/(n*k*(2*n - 3*k - 1))*sum_i)).squeeze())

def metric_neighborhood_hit(X, y, k):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X, y)

    neighbors = knn.kneighbors(X, return_distance=False)
    return np.mean(np.mean((y[neighbors] == np.tile(y.reshape((-1, 1)), k)).astype('uint8'), axis=1))


--- File: graphutil.py ---

import numpy as np

def make_graph(P, n_epochs=-1):
	graph = P.tocoo()
	graph.sum_duplicates()
	n_vertices = graph.shape[1]

	if n_epochs <= 0:
		if graph.shape[0] <= 10000:
			n_epochs = 500
		else:
			n_epochs = 200

	graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0
	graph.eliminate_zeros()
	return graph

def make_epochs_per_sample(weights, n_epochs):
	result = -1.0 * np.ones(weights.shape[0], dtype=np.float64)
	n_samples = n_epochs * (weights / weights.max())
	result[n_samples > 0] = float(n_epochs) / n_samples[n_samples > 0]
	return result

def make_epochs_per_sample_from_P(p, n_epoch, neg_rate=5):
	graph = make_graph(p, n_epoch)
	epochs_per_sample = make_epochs_per_sample(graph.data, n_epoch)
	epochs_per_negative_sample = epochs_per_sample / neg_rate
	return graph, epochs_per_sample, epochs_per_negative_sample
--- File: __init__.py ---

# __init__.py  

--- File: network.py ---

import operator
from functools import reduce

import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from functools import partial

def get_activation(act, inplace=True):
	if act == 'lrelu':
		return nn.LeakyReLU(0.01, inplace=inplace)
	elif act == 'relu':
		return nn.ReLU(inplace=inplace)
	elif act == 'sigmoid':
		return nn.Sigmoid()
	raise Exception('unsupported activation function')

class FCEncoder(nn.Module):
	def __init__(self, dim, low_dim=2, act='sigmoid'):
		super(FCEncoder, self).__init__()
		self.dim = dim
		self.act = partial(get_activation, act=act)
        
		# new network (1024 -> 512 -> 256 -> 128 -> 2)
		layers = [
			(nn.Linear(dim, 1024)),
			# (nn.BatchNorm1d(1024)),
			self.act(),
			(nn.Linear(1024, 512)),
			# (nn.BatchNorm1d(512)),
			self.act(),
			(nn.Linear(512, 256)),
			# (nn.BatchNorm1d(256)),
			self.act(),
			(nn.Linear(256, 128)),
			# (nn.BatchNorm1d(128)),
			self.act(),
			(nn.Linear(128, low_dim))
		]
        
		self.net = nn.Sequential(*layers)
		
	def forward(self, X):
		return self.net(X)

--- File: tsne_nn.py ---

import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
from openTSNE import TSNE
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import SpectralEmbedding
from scipy.sparse import save_npz, load_npz
import random
from functools import partial
import timeit
import math
from tqdm import tqdm
from .network import FCEncoder

EPS = 1e-12
D_GRAD_CLIP = 1e14

class TSNE_NN():
	def __init__(self, device, n_epochs ,hidden_dim=256, n_components=2, verbose=True, batch_size=256):
		self.device = device
		self.n_epochs = n_epochs
		self.batch_size = batch_size
		self.perplexity = 15
		self.test_data = None
		self.max_grads = []
		self.epoch_losses = []
		self.verbose = verbose
		self.hidden_dim = hidden_dim
		self.n_components = n_components
	
	def fit(self, data):
		self.encoder = FCEncoder(data.shape[1], low_dim=self.n_components)
		batch_size = self.batch_size
		print('perplexity:', self.perplexity)
		
		print('calc P')
		pre_embedding = TSNE(perplexity=self.perplexity).prepare_initial(data)
		P_csc = pre_embedding.affinities.P
			
		print('Trying to put X into GPU')
		X = torch.from_numpy(data).float()
		X = X.to(self.device)
		self.X = X

		self.encoder = self.encoder.to(self.device)
		init_lr = 1e-3
		optimizer = optim.Adam(self.encoder.parameters(), lr=init_lr)
		# optimizer = optim.AdamW(self.encoder.parameters(), lr=init_lr)
		# init_lr = 1e-3
		# optimizer = optim.SGD(self.encoder.parameters(), lr=init_lr, momentum=0.9, weight_decay=5e-4) 

		lr_sched = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.n_epochs * math.ceil(len(X)/batch_size), eta_min=1e-7)
		
		def neg_squared_euc_dists(X):
			D = torch.cdist(X, X, p=2).pow(2)
			return -D

		def w_tsne(Y):
			distances = neg_squared_euc_dists(Y)
			inv_distances = 1. / (1. - (distances)) #1 / (1+d^2)
			return inv_distances
		
		def KLD(P, Q):
			x = P/Q
			if x.requires_grad:
				def hook(grad):
					self.max_grads.append(float(grad.abs().max().cpu().numpy()))
					clipped_grad = grad.clamp(min=-D_GRAD_CLIP, max=D_GRAD_CLIP)
					return clipped_grad
				x.register_hook(hook)
			return P * torch.log(x)
		
		iteration = 0
		print('optimizing...')
		pbar = tqdm(range(self.n_epochs))
		for epoch in pbar:
			iteration += 1

			idxs = torch.randperm(len(X))
			
			loss_total = []
			update_time = []
			for i in range(0, len(X), batch_size):
				start_time = timeit.default_timer()
				idx = idxs[i:i+batch_size]
				_p = torch.Tensor(P_csc[idx][:, idx].toarray()).float()
				if iteration < 250:
					_p *= 4
				p = (_p+EPS).to(self.device)
				optimizer.zero_grad()
				y = self.encoder(X[idx])
				w = w_tsne(y)
				q = w / torch.sum(w)
				loss = KLD(p, q).sum()
				loss.backward()
				loss_total.append(loss.item())
				torch.nn.utils.clip_grad_value_(self.encoder.parameters(), 4)
				optimizer.step()
				elapsed = timeit.default_timer() - start_time
				update_time.append(elapsed)
			
				lr_sched.step()
			
			self.epoch_losses.append(np.mean(loss_total))
			if (self.verbose):
				pbar.set_description("Processing epoch %03d/%03d loss : %.5f time : %.5fs" % (epoch + 1, self.n_epochs, np.mean(loss_total), np.mean(update_time)))
				# print('{:03d}/{:03d}'.format(epoch, self.n_epochs), '{:.5f}'.format(np.mean(self.loss_total)), '{:.5f}s'.format(np.mean(update_time)))
	
		with torch.no_grad():
			result = self.encoder(self.X).detach().cpu().numpy()
        	# Normalize coordinates to [0, 1]    
			result_min, result_max = result.min(), result.max()
			result_norm = (result - result_min) / (result_max - result_min)
			return result_norm

	def fit_val(self, data):
		with torch.no_grad():
			self.X = torch.from_numpy(data).float()
			self.X = self.X.to(self.device)
			result = self.encoder(self.X).detach().cpu().numpy()
			# Normalize coordinates to [0, 1]    
			result_min, result_max = result.min(), result.max()
			result_norm = (result - result_min) / (result_max - result_min)
			return result_norm

üìÑ document/*.pdf (not extracted, only listed):

/home/kyhoolee/work/1_backend/4_financial_analysis/3_crypto/9_data_science/data_science_challenge/taiwan_phd/prof_papers/code/tw_parametric_dr/document/Parametric_t_SNE_main.pdf
/home/kyhoolee/work/1_backend/4_financial_analysis/3_crypto/9_data_science/data_science_challenge/taiwan_phd/prof_papers/code/tw_parametric_dr/document/Parametric_t_SNE_supplemental.pdf
